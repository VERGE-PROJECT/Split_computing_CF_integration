{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a4c5d7a-b8ab-403c-bd8b-166f3be27e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_lightning in /opt/conda/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: torch>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from pytorch_lightning) (2.4.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.11/site-packages (from pytorch_lightning) (4.66.5)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.11/site-packages (from pytorch_lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.9.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from pytorch_lightning) (1.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from pytorch_lightning) (22.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.11/site-packages (from pytorch_lightning) (4.12.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from pytorch_lightning) (0.11.8)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.10.9)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.1.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=2.1.0->pytorch_lightning) (3.16.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=2.1.0->pytorch_lightning) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.1.0->pytorch_lightning) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.1.0->pytorch_lightning) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.1.0->pytorch_lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.1.0->pytorch_lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.1.0->pytorch_lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=2.1.0->pytorch_lightning) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.1.0->pytorch_lightning) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=2.1.0->pytorch_lightning) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.1.0->pytorch_lightning) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=2.1.0->pytorch_lightning) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.1.0->pytorch_lightning) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.1.0->pytorch_lightning) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.1.0->pytorch_lightning) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.1.0->pytorch_lightning) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.0->pytorch_lightning) (12.6.77)\n",
      "Requirement already satisfied: numpy<2.0,>1.20.0 in /opt/conda/lib/python3.11/site-packages (from torchmetrics>=0.7.0->pytorch_lightning) (1.24.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "import cogflow as cf\n",
    "from cogflow import InputPath, OutputPath\n",
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from enum import Enum\n",
    "import random\n",
    "!pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e1aba35-9410-4ec2-ab8a-b7629226056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, max_action):\n",
    "        super(Actor, self).__init__()\n",
    "        self.l1 = nn.Linear(state_dim, 256)\n",
    "        self.l2 = nn.Linear(256, 256)\n",
    "        self.l3 = nn.Linear(256, action_dim)\n",
    "        self.max_action = max_action\n",
    "\n",
    "    def forward(self, state):\n",
    "        a = F.relu(self.l1(state))\n",
    "        a = F.relu(self.l2(a))\n",
    "        return self.max_action * torch.softmax(self.l3(a), dim=-1)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        # Q1 architecture\n",
    "        self.l1 = nn.Linear(state_dim + action_dim, 256)\n",
    "        self.l2 = nn.Linear(256, 256)\n",
    "        self.l3 = nn.Linear(256, 1)\n",
    "        \n",
    "        # Q2 architecture\n",
    "        self.l4 = nn.Linear(state_dim + action_dim, 256)\n",
    "        self.l5 = nn.Linear(256, 256)\n",
    "        self.l6 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        sa = torch.cat([state, action], 1)\n",
    "        \n",
    "        q1 = F.relu(self.l1(sa))\n",
    "        q1 = F.relu(self.l2(q1))\n",
    "        q1 = self.l3(q1)\n",
    "        \n",
    "        q2 = F.relu(self.l4(sa))\n",
    "        q2 = F.relu(self.l5(q2))\n",
    "        q2 = self.l6(q2)\n",
    "        return q1, q2\n",
    "\n",
    "    def Q1(self, state, action):\n",
    "        sa = torch.cat([state, action], 1)\n",
    "        q1 = F.relu(self.l1(sa))\n",
    "        q1 = F.relu(self.l2(q1))\n",
    "        q1 = self.l3(q1)\n",
    "        return q1\n",
    "\n",
    "class SplitComputingAgent(cf.pyfunc.PythonModel):\n",
    "    def __init__(\n",
    "            self,\n",
    "            state_dim,\n",
    "            action_dim,\n",
    "            max_action,\n",
    "            discount=0.99,\n",
    "            tau=0.005,\n",
    "            policy_noise=0.2,\n",
    "            noise_clip=0.5,\n",
    "            policy_freq=2\n",
    "    ):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.actor = Actor(state_dim, action_dim, max_action).to(self.device)\n",
    "        self.actor_target = copy.deepcopy(self.actor)\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=3e-4)\n",
    "\n",
    "        self.critic = Critic(state_dim, action_dim).to(self.device)\n",
    "        self.critic_target = copy.deepcopy(self.critic)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=3e-4)\n",
    "\n",
    "        self.max_action = max_action\n",
    "        self.discount = discount\n",
    "        self.tau = tau\n",
    "        self.policy_noise = policy_noise\n",
    "        self.noise_clip = noise_clip\n",
    "        self.policy_freq = policy_freq\n",
    "        self.total_it = 0\n",
    "\n",
    "    def select_action(self, state):\n",
    "        state = torch.FloatTensor(state.reshape(1, -1)).to(self.device)\n",
    "        return self.actor(state).cpu().data.numpy().flatten()\n",
    "\n",
    "    def train(self, replay_buffer, batch_size=256):\n",
    "        self.total_it += 1\n",
    "        \n",
    "        # Sample replay buffer\n",
    "        state, action, next_state, reward, not_done = replay_buffer.sample(batch_size)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            noise = (torch.randn_like(action) * self.policy_noise).clamp(-self.noise_clip, self.noise_clip)\n",
    "            next_action = (self.actor_target(next_state) + noise).clamp(-self.max_action, self.max_action)\n",
    "            \n",
    "            target_q1, target_q2 = self.critic_target(next_state, next_action)\n",
    "            target_q = torch.min(target_q1, target_q2)\n",
    "            target_q = reward + not_done * self.discount * target_q\n",
    "\n",
    "        current_q1, current_q2 = self.critic(state, action)\n",
    "        critic_loss = F.mse_loss(current_q1, target_q) + F.mse_loss(current_q2, target_q)\n",
    "\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        if self.total_it % self.policy_freq == 0:\n",
    "            actor_loss = -self.critic.Q1(state, self.actor(state)).mean()\n",
    "            \n",
    "            self.actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            self.actor_optimizer.step()\n",
    "\n",
    "            for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
    "                target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "            for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "                target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        return self.select_action(model_input)\n",
    "\n",
    "    def save(self, filename):\n",
    "        critic_filename = filename + \"_critic\"\n",
    "        critic_optimizer_filename = filename + \"_critic_optimizer\"\n",
    "        actor_filename = filename + \"_actor\"\n",
    "        actor_optimizer_filename = filename + \"_actor_optimizer\"\n",
    "        \n",
    "        cf.pytorch.save_state_dict(self.critic.state_dict(), critic_filename)\n",
    "        cf.pytorch.save_state_dict(self.critic_optimizer.state_dict(), critic_optimizer_filename)\n",
    "        cf.pytorch.save_state_dict(self.actor.state_dict(), actor_filename)\n",
    "        cf.pytorch.save_state_dict(self.actor_optimizer.state_dict(), actor_optimizer_filename)\n",
    "        \n",
    "        return {\n",
    "            \"criticFileName\": critic_filename,\n",
    "            \"criticOptimizerFileName\": critic_optimizer_filename,\n",
    "            \"actorFileName\": actor_filename,\n",
    "            \"actorOptimizerFileName\": actor_optimizer_filename\n",
    "        }\n",
    "\n",
    "    def load(self, filename):\n",
    "        critic_filename = filename + \"_critic\"\n",
    "        critic_optimizer_filename = filename + \"_critic_optimizer\"\n",
    "        actor_filename = filename + \"_actor\"\n",
    "        actor_optimizer_filename = filename + \"_actor_optimizer\"\n",
    "        \n",
    "        self.critic.load_state_dict(torch.load(critic_filename))\n",
    "        self.critic_optimizer.load_state_dict(torch.load(critic_optimizer_filename))\n",
    "        self.critic_target = copy.deepcopy(self.critic)\n",
    "        \n",
    "        self.actor.load_state_dict(torch.load(actor_filename))\n",
    "        self.actor_optimizer.load_state_dict(torch.load(actor_optimizer_filename))\n",
    "        self.actor_target = copy.deepcopy(self.actor)\n",
    "        \n",
    "# UE Type Enumeration\n",
    "class UEType(Enum):\n",
    "    SMARTPHONE = 1\n",
    "    TABLET = 2\n",
    "    LAPTOP = 3\n",
    "    IOT = 4\n",
    "\n",
    "# Wireless Channel Classes\n",
    "class WirelessLink:\n",
    "    def __init__(self, bandwidth):\n",
    "        self.bandwidth = bandwidth\n",
    "        self.rsrp = None\n",
    "        self.rsrq = None\n",
    "        self.sinr = None\n",
    "        self.cqi = None\n",
    "\n",
    "    def update_channel_conditions(self, rsrp, rsrq, sinr, cqi):\n",
    "        self.rsrp = rsrp\n",
    "        self.rsrq = rsrq\n",
    "        self.sinr = sinr\n",
    "        self.cqi = cqi\n",
    "\n",
    "    def data_rate(self):\n",
    "        if self.sinr is None:\n",
    "            raise ValueError(\"Channel conditions not set\")\n",
    "        return self.bandwidth * np.log2(1 + np.power(10,(self.sinr / 10)))\n",
    "\n",
    "    def latency(self, data_size):\n",
    "        return data_size / self.data_rate()\n",
    "\n",
    "class WirelessChannel:\n",
    "    def __init__(self, channel_file):\n",
    "        self.channel_data = pd.read_csv(channel_file)\n",
    "        self.channel_data['timestamp'] = pd.to_datetime(self.channel_data['timestamp'])\n",
    "        self.timestamps = sorted(self.channel_data['timestamp'].unique())\n",
    "        self.current_step = 0\n",
    "\n",
    "    def get_channel_conditions(self, ue_id, step):\n",
    "        if step >= len(self.timestamps):\n",
    "            raise ValueError(f\"Step {step} is out of range. Max step is {len(self.timestamps) - 1}\")\n",
    "\n",
    "        timestamp = self.timestamps[step]\n",
    "        conditions = self.channel_data[\n",
    "            (self.channel_data['UE_ID'] == ue_id) &\n",
    "            (self.channel_data['timestamp'] == timestamp)\n",
    "        ].iloc[0]\n",
    "\n",
    "        return {\n",
    "            'rsrp': conditions['RSRP'],\n",
    "            'rsrq': conditions['RSRQ'],\n",
    "            'sinr': conditions['SINR'],\n",
    "            'cqi': conditions['CQI']\n",
    "        }\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.current_step += 1\n",
    "        if self.current_step >= len(self.timestamps):\n",
    "            self.current_step = 0\n",
    "\n",
    "# MEC Server Class\n",
    "class MECServer:\n",
    "    def __init__(self, cpu, mem, gpu):\n",
    "        self.total_cpu = cpu  # in MIPS\n",
    "        self.total_mem = mem  # in GB\n",
    "        self.total_gpu = gpu  # in FLOPS\n",
    "\n",
    "        self.available_cpu = cpu\n",
    "        self.available_mem = mem\n",
    "        self.available_gpu = gpu\n",
    "\n",
    "        self.tasks = []\n",
    "\n",
    "    def can_accept_task(self, mem_req):\n",
    "        return self.available_mem >= mem_req\n",
    "\n",
    "    def get_utilization(self):\n",
    "        return {\n",
    "            'cpu': (self.total_cpu - self.available_cpu) / self.total_cpu,\n",
    "            'mem': (self.total_mem - self.available_mem) / self.total_mem,\n",
    "            'gpu': (self.total_gpu - self.available_gpu) / self.total_gpu\n",
    "        }\n",
    "\n",
    "    def process_task(self, cpu_demand, gpu_demand, memory_demand):\n",
    "        if self.can_accept_task(memory_demand):\n",
    "            processing_time = min(cpu_demand / self.available_cpu,\n",
    "                                gpu_demand / self.available_gpu)\n",
    "            return processing_time\n",
    "        else:\n",
    "            return float('inf')\n",
    "\n",
    "    def reset(self):\n",
    "        self.available_cpu = self.total_cpu\n",
    "        self.available_mem = self.total_mem\n",
    "        self.available_gpu = self.total_gpu\n",
    "        self.tasks = []\n",
    "\n",
    "# DNN Task Class (simplified version)\n",
    "class DNNTask:\n",
    "    def __init__(self, num_layers=4):\n",
    "        self.num_layers = num_layers\n",
    "        self.layer_demands = self._generate_layer_demands()\n",
    "\n",
    "    def _generate_layer_demands(self):\n",
    "        return [{\n",
    "            'local_cpu_demand': 1e9 * (i + 1),\n",
    "            'local_gpu_demand': 2e9 * (i + 1),\n",
    "            'local_memory_demand': 1e8 * (i + 1),\n",
    "            'remote_cpu_demand': 5e8 * (i + 1),\n",
    "            'remote_gpu_demand': 1e9 * (i + 1),\n",
    "            'remote_memory_demand': 5e7 * (i + 1),\n",
    "            'transmision_data_demand': 1e6 * (i + 1)\n",
    "        } for i in range(self.num_layers)]\n",
    "\n",
    "    def get_split_info(self, split_point):\n",
    "        if split_point < 0 or split_point > self.num_layers:\n",
    "            raise ValueError(f\"Invalid split point: {split_point}\")\n",
    "\n",
    "        local_layers = self.layer_demands[:split_point]\n",
    "        remote_layers = self.layer_demands[split_point:]\n",
    "\n",
    "        return {\n",
    "            'local_cpu_demand': sum(layer['local_cpu_demand'] for layer in local_layers),\n",
    "            'local_gpu_demand': sum(layer['local_gpu_demand'] for layer in local_layers),\n",
    "            'local_memory_demand': sum(layer['local_memory_demand'] for layer in local_layers),\n",
    "            'remote_cpu_demand': sum(layer['remote_cpu_demand'] for layer in remote_layers),\n",
    "            'remote_gpu_demand': sum(layer['remote_gpu_demand'] for layer in remote_layers),\n",
    "            'remote_memory_demand': sum(layer['remote_memory_demand'] for layer in remote_layers),\n",
    "            'transmision_data_demand': sum(layer['transmision_data_demand'] for layer in remote_layers)\n",
    "        }\n",
    "\n",
    "# UE Class\n",
    "class UE:\n",
    "    DEFAULT_RESOURCES = {\n",
    "        UEType.SMARTPHONE: {\n",
    "            \"cpu\": 2.0e9, \"gpu\": 50e9, \"mem\": 4e9, \"bat\": 3000,\n",
    "            \"e_cpu\": 1e-9, \"e_gpu\": 1e-12, \"e_mem\": 1e-6,\n",
    "            \"p_base\": 0.1, \"p_tx\": 0.5\n",
    "        },\n",
    "        UEType.TABLET: {\n",
    "            \"cpu\": 2.5e9, \"gpu\": 7e9, \"mem\": 8e9, \"bat\": 7000,\n",
    "            \"e_cpu\": 9e-10, \"e_gpu\": 9e-13, \"e_mem\": 9e-7,\n",
    "            \"p_base\": 0.15, \"p_tx\": 0.6\n",
    "        },\n",
    "        UEType.LAPTOP: {\n",
    "            \"cpu\": 3.5e9, \"gpu\": 2e12, \"mem\": 16e9, \"bat\": 5000,\n",
    "            \"e_cpu\": 8e-10, \"e_gpu\": 8e-13, \"e_mem\": 8e-7,\n",
    "            \"p_base\": 0.2, \"p_tx\": 0.7\n",
    "        },\n",
    "        UEType.IOT: {\n",
    "            \"cpu\": 1.0e9, \"gpu\": 0, \"mem\": 1e9, \"bat\": 1000,\n",
    "            \"e_cpu\": 1.2e-9, \"e_gpu\": 0, \"e_mem\": 1.2e-6,\n",
    "            \"p_base\": 0.05, \"p_tx\": 0.3\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def __init__(self, ue_id, ue_type, num_layers=4):\n",
    "        self.ue_id = ue_id\n",
    "        self.ue_type = ue_type\n",
    "        self.resources = self.DEFAULT_RESOURCES[ue_type].copy()\n",
    "        self.cpu_load = 20\n",
    "        self.gpu_load = 10 if self.resources['gpu'] > 0 else 0\n",
    "        self.mem_load = 10\n",
    "        self.bat_level = self.resources['bat']\n",
    "        self.wireless_link = WirelessLink(10e6)\n",
    "        self.task = DNNTask(num_layers=num_layers)\n",
    "        self.time = 0\n",
    "\n",
    "    def update(self):\n",
    "        self.time += 1\n",
    "        cpu_change = random.normalvariate(0, 0.05 * self.resources['cpu'])\n",
    "        self.cpu_load = max(0, min(self.resources['cpu'], self.cpu_load + cpu_change))\n",
    "\n",
    "        if self.resources['gpu'] > 0:\n",
    "            gpu_change = random.normalvariate(0, 0.07 * self.resources['gpu'])\n",
    "            self.gpu_load = max(0, min(self.resources['gpu'], self.gpu_load + gpu_change))\n",
    "\n",
    "        mem_change = random.normalvariate(0, 0.07 * self.resources['mem'])\n",
    "        self.mem_load = max(0, min(self.resources['mem'], self.mem_load + mem_change))\n",
    "\n",
    "        energy_consumption = (self.cpu_load * self.resources['e_cpu'] + \n",
    "                            self.gpu_load * self.resources['e_gpu'] + \n",
    "                            self.mem_load * self.resources['e_mem'] + \n",
    "                            self.resources['p_base']) / 3600\n",
    "        self.bat_level -= energy_consumption\n",
    "\n",
    "        if random.random() < 0.1 or self.bat_level < 0.1 * self.resources['bat']:\n",
    "            self.bat_level = self.resources['bat']\n",
    "\n",
    "    def get_state(self):\n",
    "        return {\n",
    "            'cpu_load': self.cpu_load / self.resources['cpu'],\n",
    "            'gpu_load': self.gpu_load / self.resources['gpu'] if self.resources['gpu'] > 0 else 0,\n",
    "            'mem_load': self.mem_load / self.resources['mem'],\n",
    "            'bat_level': self.bat_level / self.resources['bat'],\n",
    "            'rsrp': self.wireless_link.rsrp/100,\n",
    "            'rsrq': self.wireless_link.rsrq/20,\n",
    "            'sinr': self.wireless_link.sinr/10\n",
    "        }\n",
    "\n",
    "    def compute_local(self, cpu_demand, gpu_demand, memory_demand):\n",
    "        available_cpu = self.resources['cpu'] - self.cpu_load\n",
    "        available_gpu = self.resources['gpu'] - self.gpu_load\n",
    "        available_mem = self.resources['mem'] - self.mem_load\n",
    "\n",
    "        if available_mem < memory_demand:\n",
    "            return float('inf')\n",
    "\n",
    "        cpu_time = cpu_demand / available_cpu if available_cpu > 0 else float('inf')\n",
    "        gpu_time = gpu_demand / available_gpu if available_gpu > 0 else float('inf')\n",
    "        return min(cpu_time, gpu_time)\n",
    "\n",
    "    def compute_communication(self, data_size):\n",
    "        return self.wireless_link.latency(data_size/80)\n",
    "\n",
    "    def calculate_energy_consumption(self, cpu_usage, gpu_usage, mem_usage, duration):\n",
    "        return (cpu_usage * self.resources['e_cpu'] + \n",
    "                gpu_usage * self.resources['e_gpu'] + \n",
    "                mem_usage * self.resources['e_mem'] + \n",
    "                self.resources['p_base']) * duration\n",
    "\n",
    "# Split Computing Environment\n",
    "class SplitComputingEnv:\n",
    "    def __init__(self, channel_file, num_ues):\n",
    "        super(SplitComputingEnv, self).__init__()\n",
    "        self.channel_data = pd.read_csv(channel_file)\n",
    "        distinct_ue_ids = self.channel_data['UE_ID'].nunique()\n",
    "        self.max_steps = self.channel_data['timestamp'].nunique()\n",
    "\n",
    "        if num_ues > distinct_ue_ids:\n",
    "            raise ValueError(f\"Requested number of UEs ({num_ues}) exceeds the number of distinct UE IDs in the channel file ({distinct_ue_ids})\")\n",
    "\n",
    "        self.num_ues = num_ues\n",
    "        self.wireless_channel = WirelessChannel(channel_file)\n",
    "        self.action_space = 5\n",
    "        self.observation_space = 7\n",
    "        self.actual_ue_ids = self.channel_data['UE_ID'].unique()[:num_ues]\n",
    "\n",
    "        ue_type_probabilities = [0.5, 0.15, 0.25, 0.1]\n",
    "        ue_types = np.random.choice(list(UEType), size=num_ues, p=ue_type_probabilities)\n",
    "        self.ues = {ue_id: UE(int(ue_id), ue_type, num_layers=self.action_space) \n",
    "                   for ue_id, ue_type in zip(self.actual_ue_ids, ue_types)}\n",
    "\n",
    "        self.mec_server = MECServer(cpu=100e9, mem=256e9, gpu=1e12)\n",
    "        self.current_step = 0\n",
    "        self.ues_processed_this_step = set()\n",
    "        self.total_energy_consumed = {ue_id: [] for ue_id in self.actual_ue_ids}\n",
    "        self.total_time_taken = {ue_id: [] for ue_id in self.actual_ue_ids}\n",
    "        self.ue_data_rate = {ue_id: [] for ue_id in self.actual_ue_ids}\n",
    "        self.sla_violation = {ue_id: 0 for ue_id in self.actual_ue_ids}\n",
    "\n",
    "    def step(self, action, ue_id):\n",
    "        if ue_id not in self.ues:\n",
    "            raise ValueError(f\"Invalid UE ID: {ue_id}\")\n",
    "        energy_consumption = 0\n",
    "        ue = self.ues[ue_id]\n",
    "        ue.update()\n",
    "        channel_conditions = self.wireless_channel.get_channel_conditions(ue_id, self.current_step)\n",
    "        ue.wireless_link.update_channel_conditions(**channel_conditions)\n",
    "\n",
    "        split_info = ue.task.get_split_info(action)\n",
    "        local_time = ue.compute_local(split_info['local_cpu_demand'], split_info['local_gpu_demand'],\n",
    "                                      split_info['local_memory_demand'])\n",
    "        comm_time = ue.compute_communication(split_info['transmision_data_demand'])\n",
    "\n",
    "        if self.mec_server.can_accept_task(split_info['remote_memory_demand']):\n",
    "            remote_time = self.mec_server.process_task(split_info['remote_cpu_demand'], split_info['remote_gpu_demand'],\n",
    "                                                       split_info['remote_memory_demand'])\n",
    "        else:\n",
    "            remote_time = float('inf')\n",
    "\n",
    "        total_time = local_time + comm_time + remote_time\n",
    "        if total_time <float('inf'):\n",
    "            energy_consumption = ue.calculate_energy_consumption(\n",
    "                split_info['local_cpu_demand'],\n",
    "                split_info['local_gpu_demand'],\n",
    "                split_info['local_memory_demand'],\n",
    "                local_time\n",
    "            ) + ue.resources['p_tx'] * comm_time\n",
    "            self.total_energy_consumed[ue_id].append(energy_consumption)\n",
    "            self.total_time_taken[ue_id].append(total_time)\n",
    "            self.ue_data_rate[ue_id].append(ue.wireless_link.data_rate())\n",
    "            reward = self.compute_reward(total_time, energy_consumption, ue.bat_level / ue.resources['bat'])\n",
    "        else:\n",
    "            self.sla_violation[ue_id] += 1\n",
    "            reward = -1\n",
    "\n",
    "\n",
    "        self.ues_processed_this_step.add(ue_id)\n",
    "\n",
    "        # Check if all UEs have been processed for this step\n",
    "        if len(self.ues_processed_this_step) == self.num_ues:\n",
    "            self.current_step += 1\n",
    "            self.ues_processed_this_step.clear()\n",
    "\n",
    "        done = self.current_step >= self.max_steps\n",
    "        info = {\n",
    "            'energy_consumption': energy_consumption,\n",
    "            'total_time': total_time\n",
    "        }\n",
    "        return ue.get_state(), reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.ues_processed_this_step.clear()\n",
    "        self.total_energy_consumed = {ue_id: [] for ue_id in self.actual_ue_ids}\n",
    "        self.total_time_taken = {ue_id: [] for ue_id in self.actual_ue_ids}\n",
    "        self.ue_data_rate = {ue_id: [] for ue_id in self.actual_ue_ids}\n",
    "        self.sla_violation = {ue_id: 0 for ue_id in self.actual_ue_ids}\n",
    "        # Reset UEs and update their initial channel conditions\n",
    "        initial_states = {}\n",
    "        for ue_id, ue in self.ues.items():\n",
    "            ue.__init__(ue.ue_id, ue.ue_type)  # Reset UE to initial state\n",
    "\n",
    "            # Get initial channel conditions for this UE\n",
    "            initial_conditions = self.wireless_channel.get_channel_conditions(ue_id, self.current_step)\n",
    "\n",
    "            # Update UE's wireless link with initial conditions\n",
    "            ue.wireless_link.update_channel_conditions(**initial_conditions)\n",
    "\n",
    "            # Get the initial state for this UE\n",
    "            initial_states[ue_id] = ue.get_state()\n",
    "\n",
    "        self.mec_server.reset()\n",
    "        self.current_step += 1\n",
    "        return initial_states\n",
    "\n",
    "    def compute_reward(self, delay, energy, battery_level):\n",
    "        # before computing the reward we normalize the delay and energy:\n",
    "        delay = delay*10\n",
    "        energy = energy / 10\n",
    "        w1, w2, w3 = 0.4, 0.4, 0.2\n",
    "        r_time = 1 / (delay + 1e-6)\n",
    "        r_energy = 1 / (energy + 1e-6)\n",
    "        r_battery = battery_level\n",
    "        return w1 * r_time + w2 * r_energy + w3 * r_battery\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "    def get_average_energy_consumption(self):\n",
    "        return {ue_id: np.array(self.total_energy_consumed[ue_id]).mean() for ue_id in self.total_energy_consumed.keys()}\n",
    "\n",
    "    def get_average_total_time(self):\n",
    "        return {ue_id: (np.array(self.total_time_taken[ue_id])*100).mean() for ue_id in self.total_time_taken.keys()}\n",
    "\n",
    "    def get_total_sla_violation(self):\n",
    "        return {ue_id: self.sla_violation[ue_id] for ue_id in self.sla_violation.items()}\n",
    "\n",
    "    def get_total_data_rate(self):\n",
    "        return  self.ue_data_rate\n",
    "    def get_overall_average_energy_consumption(self):\n",
    "\n",
    "        means = [np.mean(energy) for energy in self.total_energy_consumed.values() if len(energy) > 0]\n",
    "        result = np.mean(means) if means else 0\n",
    "        return result\n",
    "\n",
    "    def get_overall_average_total_time(self):\n",
    "\n",
    "        means = [np.mean(time) *100 for time in self.total_time_taken.values() if len(time) > 0]\n",
    "        result = np.mean(means) if means else 0\n",
    "        return result\n",
    "\n",
    "    def get_overall_ue_data_rate(self):\n",
    "\n",
    "        means = [np.mean(rate)/1e6 for rate in self.ue_data_rate.values() if len(rate) > 0]\n",
    "        result = np.mean(means) if means else 0\n",
    "        return result\n",
    "\n",
    "    def get_overall_average_sla_violation(self):\n",
    "        violations = [arr for arr in self.sla_violation.values()]\n",
    "        return np.mean(violations)\n",
    "        \n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, size):\n",
    "        \"\"\"Create Replay buffer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        size: int\n",
    "            Max number of transitions to store in the buffer. When the buffer\n",
    "            overflows the old memories are dropped.\n",
    "        \"\"\"\n",
    "        self._storage = []\n",
    "        self._maxsize = size\n",
    "        self._next_idx = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._storage)\n",
    "\n",
    "    def add(self, obs_t, action, reward, obs_tp1, done):\n",
    "        data = (obs_t, action, reward, obs_tp1, done)\n",
    "\n",
    "        if self._next_idx >= len(self._storage):\n",
    "            self._storage.append(data)\n",
    "        else:\n",
    "            self._storage[self._next_idx] = data\n",
    "        self._next_idx = (self._next_idx + 1) % self._maxsize\n",
    "\n",
    "    def _encode_sample(self, idxes):\n",
    "        obses_t, actions, rewards, obses_tp1, dones = [], [], [], [], []\n",
    "        for i in idxes:\n",
    "            data = self._storage[i]\n",
    "            obs_t, action, reward, obs_tp1, done = data\n",
    "            obses_t.append(np.array(obs_t, copy=False))\n",
    "            actions.append(np.array(action, copy=False))\n",
    "            rewards.append(reward)\n",
    "            obses_tp1.append(np.array(obs_tp1, copy=False))\n",
    "            dones.append(done)\n",
    "        return np.array(obses_t), np.array(actions), np.array(rewards), np.array(obses_tp1), np.array(dones)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of experiences.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size: int\n",
    "            How many transitions to sample.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        obs_batch: np.array\n",
    "            batch of observations\n",
    "        act_batch: np.array\n",
    "            batch of actions executed given obs_batch\n",
    "        rew_batch: np.array\n",
    "            rewards received as results of executing act_batch\n",
    "        next_obs_batch: np.array\n",
    "            next set of observations seen after executing act_batch\n",
    "        done_mask: np.array\n",
    "            done_mask[i] = 1 if executing act_batch[i] resulted in\n",
    "            the end of an episode and 0 otherwise.\n",
    "        \"\"\"\n",
    "        idxes = [random.randint(0, len(self._storage) - 1) for _ in range(batch_size)]\n",
    "        return self._encode_sample(idxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78beeb36-281d-46b5-8b5f-c88bbab53970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel Data Generation Component\n",
    "def generate_channel_data_op(num_ues: int, \n",
    "                           duration_minutes: int,\n",
    "                           sampling_rate_ms: int,\n",
    "                           output_file: OutputPath('CSV')):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from datetime import datetime, timedelta\n",
    "    \n",
    "    # [Previous generate_3gpp_channel_data function code]\n",
    "    # Generate the channel data and save to output_file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \"\"\"\n",
    "    Generate channel data following 3GPP specifications for urban macro cell scenarios.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    num_ues : int\n",
    "        Number of UEs to simulate\n",
    "    duration_minutes : int\n",
    "        Duration of the simulation in minutes\n",
    "    sampling_rate_ms : int\n",
    "        Sampling rate in milliseconds\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Path to the generated CSV file\n",
    "    \n",
    "    Notes:\n",
    "    ------\n",
    "    Following 3GPP TR 38.901 for channel modeling:\n",
    "    - Path loss model: Urban Macro (UMa)\n",
    "    - Frequency: 2GHz\n",
    "    - BS height: 25m\n",
    "    - UE height: 1.5m\n",
    "    - Distance range: 10-500m\n",
    "    \"\"\"\n",
    "    \n",
    "    def calculate_path_loss(distance, f_c=2.0):\n",
    "        \"\"\"Calculate path loss based on 3GPP UMa model\"\"\"\n",
    "        # 3GPP TR 38.901 Urban Macro path loss model\n",
    "        h_BS = 25  # Base station height in meters\n",
    "        h_UT = 1.5  # User terminal height in meters\n",
    "        \n",
    "        # Calculate break point distance\n",
    "        h_E = 1  # Effective environment height\n",
    "        h_BP = 4 * (h_BS - h_E) * (h_UT - h_E) * f_c / 0.3\n",
    "        \n",
    "        if distance < h_BP:\n",
    "            # LOS path loss before break point\n",
    "            PL = 28.0 + 22*np.log10(distance) + 20*np.log10(f_c)\n",
    "        else:\n",
    "            # LOS path loss after break point\n",
    "            PL = 28.0 + 40*np.log10(distance) + 20*np.log10(f_c) - 9*np.log10(h_BP**2 + (h_BS-h_UT)**2)\n",
    "        \n",
    "        return PL\n",
    "\n",
    "    def generate_shadow_fading(size):\n",
    "        \"\"\"Generate shadow fading with log-normal distribution\"\"\"\n",
    "        # 3GPP specifies 4dB standard deviation for UMa LOS\n",
    "        return np.random.normal(0, 4, size)\n",
    "    \n",
    "    def calculate_sinr(path_loss, shadow_fading, interference_power=-90):\n",
    "        \"\"\"Calculate SINR based on path loss and interference\"\"\"\n",
    "        tx_power = 43  # BS transmission power in dBm (typical macro cell)\n",
    "        noise_floor = -174 + 10*np.log10(20e6)  # Thermal noise for 20MHz bandwidth\n",
    "        \n",
    "        # Received power = Tx power - path loss + shadow fading\n",
    "        rx_power = tx_power - path_loss + shadow_fading\n",
    "        \n",
    "        # SINR calculation\n",
    "        interference_plus_noise = 10*np.log10(10**(interference_power/10) + 10**(noise_floor/10))\n",
    "        sinr = rx_power - interference_plus_noise\n",
    "        \n",
    "        return sinr\n",
    "    \n",
    "    def map_sinr_to_cqi(sinr):\n",
    "        \"\"\"Map SINR to CQI according to 3GPP specifications\"\"\"\n",
    "        # Simplified CQI mapping based on SINR ranges\n",
    "        cqi_ranges = [\n",
    "            (-float('inf'), -6.9),\n",
    "            (-6.9, -5.1), (-5.1, -3.3), (-3.3, -1.5), (-1.5, 0.3),\n",
    "            (0.3, 2.1), (2.1, 3.9), (3.9, 5.7), (5.7, 7.5),\n",
    "            (7.5, 9.3), (9.3, 11.1), (11.1, 12.9), (12.9, 14.7),\n",
    "            (14.7, 16.5), (16.5, float('inf'))\n",
    "        ]\n",
    "        \n",
    "        for cqi, (min_sinr, max_sinr) in enumerate(cqi_ranges):\n",
    "            if min_sinr <= sinr < max_sinr:\n",
    "                return cqi + 1\n",
    "        return 15\n",
    "    \n",
    "    def calculate_rsrp(path_loss, shadow_fading):\n",
    "        \"\"\"Calculate RSRP based on path loss\"\"\"\n",
    "        tx_power = 43  # BS transmission power in dBm\n",
    "        return tx_power - path_loss + shadow_fading\n",
    "    \n",
    "    def calculate_rsrq(rsrp, num_resource_blocks=100):\n",
    "        \"\"\"Calculate RSRQ based on RSRP and RSSI\"\"\"\n",
    "        # Simplified RSRQ calculation\n",
    "        noise_per_rb = -120  # Noise per resource block in dBm\n",
    "        rssi = 10*np.log10(10**(rsrp/10) + num_resource_blocks * 10**(noise_per_rb/10))\n",
    "        rsrq = rsrp - rssi + 10*np.log10(num_resource_blocks)\n",
    "        return np.clip(rsrq, -19.5, -3)\n",
    "\n",
    "    # Calculate number of samples\n",
    "    num_samples = int((duration_minutes * 60 * 1000) / sampling_rate_ms)\n",
    "    timestamps = [datetime.now() + timedelta(milliseconds=i*sampling_rate_ms) for i in range(num_samples)]\n",
    "    \n",
    "    # Generate UE distances (assuming some mobility)\n",
    "    ue_distances = {ue_id: [] for ue_id in range(num_ues)}\n",
    "    for ue_id in range(num_ues):\n",
    "        # Initial distance\n",
    "        current_distance = np.random.uniform(10, 500)\n",
    "        # Random walk for distance changes\n",
    "        for _ in range(num_samples):\n",
    "            # Add some random movement (-2 to +2 meters per sample)\n",
    "            current_distance += np.random.uniform(-2, 2)\n",
    "            current_distance = np.clip(current_distance, 10, 500)  # Keep within valid range\n",
    "            ue_distances[ue_id].append(current_distance)\n",
    "    \n",
    "    # Generate data for each UE and timestamp\n",
    "    data = []\n",
    "    for t_idx, timestamp in enumerate(timestamps):\n",
    "        for ue_id in range(num_ues):\n",
    "            distance = ue_distances[ue_id][t_idx]\n",
    "            path_loss = calculate_path_loss(distance)\n",
    "            shadow_fading = generate_shadow_fading(1)[0]\n",
    "            \n",
    "            # Calculate channel conditions\n",
    "            rsrp = calculate_rsrp(path_loss, shadow_fading)\n",
    "            rsrq = calculate_rsrq(rsrp)\n",
    "            sinr = calculate_sinr(path_loss, shadow_fading)\n",
    "            cqi = map_sinr_to_cqi(sinr)\n",
    "            \n",
    "            data.append({\n",
    "                'timestamp': timestamp,\n",
    "                'UE_ID': ue_id,\n",
    "                'RSRP': round(rsrp, 2),\n",
    "                'RSRQ': round(rsrq, 2),\n",
    "                'SINR': round(sinr, 2),\n",
    "                'CQI': int(cqi),\n",
    "                'distance': round(distance, 2)\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    df = pd.DataFrame(data)\n",
    "    output_file = 'channel_data_3gpp.csv'\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n=== Channel Data Statistics ===\")\n",
    "    print(f\"Number of UEs: {num_ues}\")\n",
    "    print(f\"Duration: {duration_minutes} minutes\")\n",
    "    print(f\"Sampling rate: {sampling_rate_ms}ms\")\n",
    "    print(\"\\nMetrics ranges:\")\n",
    "    for metric in ['RSRP', 'RSRQ', 'SINR', 'CQI']:\n",
    "        print(f\"{metric}: {df[metric].min():.2f} to {df[metric].max():.2f}\")\n",
    "\n",
    "channel_gen_op = cf.create_component_from_func(\n",
    "    func=generate_channel_data_op,\n",
    "    output_component_file='channel-gen-component.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "778fb0a7-d5f6-46eb-bc8e-2d3ab6933668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Setup Component\n",
    "def setup_environment_op(channel_file: InputPath('CSV'),\n",
    "                        num_ues: int,\n",
    "                        output_config: OutputPath('JSON')):\n",
    "    import json\n",
    "    from UE import UE, UEType\n",
    "    from wireless_channel import WirelessChannel\n",
    "    from mec_server import MECServer\n",
    "    \n",
    "    # Initialize environment configuration\n",
    "    config = {\n",
    "        'num_ues': num_ues,\n",
    "        'action_space': 5,\n",
    "        'observation_space': 7,\n",
    "        'mec_server': {\n",
    "            'cpu': 100e9,\n",
    "            'mem': 256e9,\n",
    "            'gpu': 1e12\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(output_config, 'w') as f:\n",
    "        json.dump(config, f)\n",
    "\n",
    "setup_env_op = cf.create_component_from_func(\n",
    "    func=setup_environment_op,\n",
    "    output_component_file='setup-env-component.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ad934-99c1-41db-9653-0d1f2d0a6814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training Component\n",
    "def train_model_op(channel_file: InputPath('CSV'),\n",
    "                  env_config: InputPath('JSON'),\n",
    "                  max_timesteps: int,\n",
    "                  batch_size: int) -> str:\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import cogflow as cf\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Initialize environment and agent\n",
    "    cf.pytorch.autolog()\n",
    "    \n",
    "    with cf.start_run() as run:\n",
    "        # Training loop\n",
    "         # Log parameters\n",
    "        cf.log_param(\"num_ues\", num_ues)\n",
    "        cf.log_param(\"seed\", seed)\n",
    "        cf.log_param(\"batch_size\", batch_size)\n",
    "        cf.log_param(\"discount\", discount)\n",
    "        cf.log_param(\"start_timesteps\", start_timesteps)\n",
    "        \n",
    "        # Training loop\n",
    "        states = env.reset()\n",
    "        episode_num = 0\n",
    "        \n",
    "        for t in tqdm(range(int(max_timesteps)), desc=\"Training Progress\"):\n",
    "            episode_rewards = {ue_id: 0 for ue_id in env.actual_ue_ids}\n",
    "            done = False\n",
    "            \n",
    "            while not done:\n",
    "                for ue_id in env.actual_ue_ids:\n",
    "                    state = states[ue_id]\n",
    "                    \n",
    "                    # Select action\n",
    "                    if t < start_timesteps:\n",
    "                        action = np.random.randint(0, env.action_space)\n",
    "                    else:\n",
    "                        action = agent.select_action(np.array(state))\n",
    "                        action = np.clip(\n",
    "                            action + np.random.normal(0, max_action * expl_noise),\n",
    "                            0,\n",
    "                            max_action\n",
    "                        )\n",
    "                    \n",
    "                    # Execute action\n",
    "                    next_state, reward, done, info = env.step(int(action), ue_id)\n",
    "                    \n",
    "                    # Store transition\n",
    "                    replay_buffer.add(state, action, next_state, reward, float(done))\n",
    "                    \n",
    "                    episode_rewards[ue_id] += reward\n",
    "                    states[ue_id] = next_state\n",
    "                    \n",
    "                    # Train agent\n",
    "                    if t >= start_timesteps:\n",
    "                        agent.train(replay_buffer, batch_size)\n",
    "            \n",
    "            # Log metrics\n",
    "            avg_energy = env.get_overall_average_energy_consumption()\n",
    "            avg_time = env.get_overall_average_total_time()\n",
    "            avg_data_rate = env.get_overall_ue_data_rate()\n",
    "            avg_violations = env.get_overall_average_sla_violation()\n",
    "            \n",
    "            cf.log_metric(\"average_energy\", avg_energy, step=episode_num)\n",
    "            cf.log_metric(\"average_time\", avg_time, step=episode_num)\n",
    "            cf.log_metric(\"average_data_rate\", avg_data_rate, step=episode_num)\n",
    "            cf.log_metric(\"sla_violations\", avg_violations, step=episode_num)\n",
    "        \n",
    "        # Save model\n",
    "        model_name = \"split-computing-model\"\n",
    "        result = cf.log_model(agent, \"model\", \n",
    "                            registered_model_name=model_name)\n",
    "        return f\"{run.info.artifact_uri}/{result.artifact_path}\"\n",
    "\n",
    "train_op = cf.create_component_from_func(\n",
    "    func=train_model_op,\n",
    "    output_component_file='train-component.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b0684-2d66-45ea-9542-b462c6bd19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Component\n",
    "def evaluate_model_op(model_path: str,\n",
    "                     channel_file: InputPath('CSV'),\n",
    "                     env_config: InputPath('JSON')):\n",
    "    import json\n",
    "    from tqdm import tqdm\n",
    "    import torch\n",
    "    \n",
    "    cf.autolog()\n",
    "    \n",
    "    with cf.start_run() as run:\n",
    "        # Load model and configuration\n",
    "        model = cf.pyfunc.load_model(model_path)\n",
    "        with open(env_config, 'r') as f:\n",
    "            config = json.load(f)\n",
    "            \n",
    "        # Initialize environment\n",
    "        env = SplitComputingEnv(channel_file, num_ues=config['num_ues'])\n",
    "        \n",
    "        # Evaluation parameters\n",
    "        n_evaluation_episodes = 100\n",
    "        results = {\n",
    "            'energy_consumption': [],\n",
    "            'processing_time': [],\n",
    "            'data_rate': [],\n",
    "            'sla_violations': [],\n",
    "            'split_decisions': [],\n",
    "            'rewards': []\n",
    "        }\n",
    "        \n",
    "        # Run evaluation episodes\n",
    "        for episode in tqdm(range(n_evaluation_episodes), desc=\"Evaluating\"):\n",
    "            episode_reward = 0\n",
    "            states = env.reset()\n",
    "            done = False\n",
    "            \n",
    "            while not done:\n",
    "                for ue_id in env.actual_ue_ids:\n",
    "                    state = states[ue_id]\n",
    "                    # Get model prediction\n",
    "                    action = model.predict(np.array(state))\n",
    "                    split_point = int(np.argmax(action))\n",
    "                    \n",
    "                    # Execute action\n",
    "                    next_state, reward, done, info = env.step(split_point, ue_id)\n",
    "                    \n",
    "                    # Record metrics\n",
    "                    results['energy_consumption'].append(info['energy_consumption'])\n",
    "                    results['processing_time'].append(info['total_time'])\n",
    "                    results['split_decisions'].append(split_point)\n",
    "                    results['rewards'].append(reward)\n",
    "                    results['data_rate'].append(env.get_total_data_rate()[ue_id][-1])\n",
    "                    \n",
    "                    states[ue_id] = next_state\n",
    "                    episode_reward += reward\n",
    "            \n",
    "            results['sla_violations'].append(env.get_overall_average_sla_violation())\n",
    "        \n",
    "        # Calculate overall metrics\n",
    "        avg_energy = np.mean(results['energy_consumption'])\n",
    "        avg_time = np.mean(results['processing_time'])\n",
    "        avg_data_rate = np.mean(results['data_rate'])\n",
    "        avg_sla_violations = np.mean(results['sla_violations'])\n",
    "        avg_reward = np.mean(results['rewards'])\n",
    "        \n",
    "        # Log metrics to cogflow\n",
    "        cf.log_metric(\"average_energy_consumption\", avg_energy)\n",
    "        cf.log_metric(\"average_processing_time\", avg_time)\n",
    "        cf.log_metric(\"average_data_rate\", avg_data_rate)\n",
    "        cf.log_metric(\"average_sla_violations\", avg_sla_violations)\n",
    "        cf.log_metric(\"average_reward\", avg_reward)\n",
    "        \n",
    "        # Log split point distribution\n",
    "        split_dist = pd.Series(results['split_decisions']).value_counts().to_dict()\n",
    "        cf.log_dict(\"split_point_distribution\", split_dist)\n",
    "        \n",
    "        # Create and log detailed performance analysis\n",
    "        performance_df = pd.DataFrame({\n",
    "            'Energy': results['energy_consumption'],\n",
    "            'Time': results['processing_time'],\n",
    "            'DataRate': results['data_rate'],\n",
    "            'SplitPoint': results['split_decisions'],\n",
    "            'Reward': results['rewards']\n",
    "        })\n",
    "        \n",
    "        # Calculate per-split-point statistics\n",
    "        split_stats = performance_df.groupby('SplitPoint').agg({\n",
    "            'Energy': ['mean', 'std'],\n",
    "            'Time': ['mean', 'std'],\n",
    "            'DataRate': ['mean', 'std'],\n",
    "            'Reward': ['mean', 'std']\n",
    "        }).round(4)\n",
    "        \n",
    "        # Log split point performance statistics\n",
    "        cf.log_dict(\"split_point_statistics\", split_stats.to_dict())\n",
    "        \n",
    "        # Calculate correlation matrix\n",
    "        corr_matrix = performance_df.corr().round(4)\n",
    "        cf.log_dict(\"metric_correlations\", corr_matrix.to_dict())\n",
    "        \n",
    "        # Log distribution plots\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        \n",
    "        # Energy distribution per split point\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(data=performance_df, x='SplitPoint', y='Energy')\n",
    "        plt.title('Energy Consumption Distribution per Split Point')\n",
    "        plt.xlabel('Split Point')\n",
    "        plt.ylabel('Energy (J)')\n",
    "        cf.log_figure(\"energy_distribution\", plt.gcf())\n",
    "        plt.close()\n",
    "        \n",
    "        # Processing time distribution per split point\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(data=performance_df, x='SplitPoint', y='Time')\n",
    "        plt.title('Processing Time Distribution per Split Point')\n",
    "        plt.xlabel('Split Point')\n",
    "        plt.ylabel('Time (ms)')\n",
    "        cf.log_figure(\"time_distribution\", plt.gcf())\n",
    "        plt.close()\n",
    "        \n",
    "        # Create summary report\n",
    "        summary = {\n",
    "            \"evaluation_episodes\": n_evaluation_episodes,\n",
    "            \"average_metrics\": {\n",
    "                \"energy_consumption\": float(avg_energy),\n",
    "                \"processing_time\": float(avg_time),\n",
    "                \"data_rate\": float(avg_data_rate),\n",
    "                \"sla_violations\": float(avg_sla_violations),\n",
    "                \"reward\": float(avg_reward)\n",
    "            },\n",
    "            \"split_point_distribution\": split_dist,\n",
    "            \"performance_summary\": \"Success\" if avg_sla_violations < 0.1 else \"Needs Improvement\"\n",
    "        }\n",
    "        \n",
    "        # Log summary\n",
    "        cf.log_dict(\"evaluation_summary\", summary)\n",
    "        \n",
    "        return {\n",
    "            \"average_energy\": avg_energy,\n",
    "            \"average_time\": avg_time,\n",
    "            \"average_data_rate\": avg_data_rate,\n",
    "            \"sla_violations\": avg_sla_violations,\n",
    "            \"average_reward\": avg_reward\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5df683f-22da-45e1-9f1d-63512ab71d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.pipeline(\n",
    "    name=\"split-computing-pipeline\",\n",
    "    description=\"Split Computing DRL Training Pipeline\"\n",
    ")\n",
    "def split_computing_pipeline(\n",
    "    num_ues: int = 3,\n",
    "    duration_minutes: int = 1000,\n",
    "    sampling_rate_ms: int = 100,\n",
    "    max_timesteps: int = 100000,\n",
    "    batch_size: int = 256\n",
    "):\n",
    "    # Generate channel data\n",
    "    channel_data_task = channel_gen_op(\n",
    "        num_ues=num_ues,\n",
    "        duration_minutes=duration_minutes,\n",
    "        sampling_rate_ms=sampling_rate_ms\n",
    "    )\n",
    "    \n",
    "    # Setup environment\n",
    "    env_setup_task = setup_env_op(\n",
    "        channel_file=channel_data_task.outputs['output_file'],\n",
    "        num_ues=num_ues\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    train_task = train_op(\n",
    "        channel_file=channel_data_task.outputs['output_file'],\n",
    "        env_config=env_setup_task.outputs['output_config'],\n",
    "        max_timesteps=max_timesteps,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    eval_task = eval_op(\n",
    "        model_path=train_task.output,\n",
    "        channel_file=channel_data_task.outputs['output_file'],\n",
    "        env_config=env_setup_task.outputs['output_config']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e0363-5679-4885-b34a-b9d6823d7d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Pipeline\n",
    "def run_pipeline():\n",
    "    client = cf.client()\n",
    "    client.create_run_from_pipeline_func(\n",
    "        split_computing_pipeline,\n",
    "        arguments={\n",
    "            \"num_ues\": 3,\n",
    "            \"duration_minutes\": 1000,\n",
    "            \"sampling_rate_ms\": 100,\n",
    "            \"max_timesteps\": 100000,\n",
    "            \"batch_size\": 256\n",
    "        }\n",
    "    )\n",
    "\n",
    "run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
